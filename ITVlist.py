import asyncio
import aiohttp
import re
import datetime
import requests
import os
import time
from urllib.parse import urljoin

URL_FILE = "https://raw.githubusercontent.com/kakaxi-1/zubo/main/ip_urls.txt"

CHANNEL_CATEGORIES = {
    "å…¨éƒ¨é¢‘é“":
    [
        "CCTV1", "CCTV2", "CCTV3", "CCTV4", "CCTV5","CCTV6", "CCTV7","CCTV8", "CCTV9",
        "CCTV10", "CCTV11", "CCTV12", "CCTV13", "CCTV14", "CCTV15", "CCTV16", "CCTV17", 
        "å®‰å¾½å«è§†","åŒ—äº¬å«è§†","ä¸œæ–¹å«è§†","ä¸œå—å«è§†","å¹¿ä¸œå«è§†","å¹¿è¥¿å«è§†","è´µå·å«è§†","æµ·å—å«è§†","æ²³åŒ—å«è§†","æ²³å—å«è§†",
        "æ¹–åŒ—å«è§†","æ¹–å—å«è§†","å‰æ—å«è§†","æ±Ÿè‹å«è§†","æ±Ÿè¥¿å«è§†","è¾½å®å«è§†","å®å¤å«è§†","é’æµ·å«è§†","å±±ä¸œå«è§†","å±±è¥¿å«è§†",
        "é™•è¥¿å«è§†","æ·±åœ³å«è§†","å››å·å«è§†","å¤©æ´¥å«è§†","äº‘å—å«è§†","æµ™æ±Ÿå«è§†","é‡åº†å«è§†","ç”˜è‚ƒå«è§†","è¥¿è—å«è§†","é¦™æ¸¯å«è§†",
        "æ–°ç–†å«è§†","ä¸‰æ²™å«è§†","å…µå›¢å«è§†","å»¶è¾¹å«è§†","é»‘é¾™æ±Ÿå«è§†","å†…è’™å¤å«è§†"
    ],
}

CHANNEL_MAPPING = {
    "CCTV1":["CCTV-1","CCTV-01","CCTV1-ç»¼åˆ","CCTV-1ç»¼åˆ","CCTV-1ç»¼åˆ","CCTV1HD","CCTV-1é«˜æ¸…","CCTV-1HD","cctv-1HD","CCTV1ç»¼åˆé«˜æ¸…","cctv1"],
    "CCTV2":["CCTV-2","CCTV-02","CCTV2-è´¢ç»","CCTV-2è´¢ç»","CCTV-2è´¢ç»","CCTV2HD","CCTV-2é«˜æ¸…","CCTV-2HD","cctv-2HD","CCTV2è´¢ç»é«˜æ¸…","cctv2"],
    "CCTV3":["CCTV-3","CCTV-03","CCTV3-ç»¼è‰º","CCTV-3ç»¼è‰º","CCTV-3ç»¼è‰º","CCTV3HD","CCTV-3é«˜æ¸…","CCTV-3HD","cctv-3HD","CCTV3ç»¼è‰ºé«˜æ¸…","cctv3"],
    "CCTV4":["CCTV-4","CCTV-04","CCTV4-å›½é™…","CCTV-4ä¸­æ–‡å›½é™…","CCTV-4ä¸­æ–‡å›½é™…","CCTV4HD","cctv4HD","CCTV-4HD","CCTV4-ä¸­æ–‡å›½é™…","CCTV4å›½é™…é«˜æ¸…","cctv4"],
    "CCTV5":["CCTV-5","CCTV-05","CCTV5-ä½“è‚²","CCTV-5ä½“è‚²","CCTV-5ä½“è‚²","CCTV5HD","CCTV-5é«˜æ¸…","CCTV-5HD","CCTV5ä½“è‚²","CCTV5ä½“è‚²é«˜æ¸…","cctv5"],
    #"CCTV5+":["CCTV-5+","CCTV5+ä½“è‚²èµ›äº‹","CCTV-5+ä½“è‚²èµ›äº‹","CCTV5+ä½“è‚²èµ›äº‹","CCTV5+HD","CCTV-5+é«˜æ¸…","CCTV-5+HD","cctv-5+HD","CCTV5plas","CCTV5+ä½“è‚²èµ›è§†é«˜æ¸…","cctv5+"],
    "CCTV6":["CCTV-6","CCTV-06","CCTV6-ç”µå½±","CCTV-6ç”µå½±","CCTV-6ç”µå½±","CCTV6HD","CCTV-6é«˜æ¸…","CCTV-6HD","cctv-6HD","CCTV6ç”µå½±é«˜æ¸…","cctv6"],
    "CCTV7":["CCTV-7","CCTV-07","CCTV7-å†›å†œ","CCTV-7å›½é˜²å†›äº‹","CCTV-7å›½é˜²å†›äº‹","CCTV7HD","CCTV-7é«˜æ¸…","CCTV-7HD","CCTV7-å›½é˜²å†›äº‹","CCTV7å†›äº‹é«˜æ¸…","cctv7"],
    "CCTV8":["CCTV-8","CCTV-08","CCTV8-ç”µè§†å‰§","CCTV-8ç”µè§†å‰§","CCTV-8ç”µè§†å‰§","CCTV8HD","CCTV-8é«˜æ¸…","CCTV-8HD","cctv-8HD","CCTV8ç”µè§†å‰§é«˜æ¸…","cctv8"],
    "CCTV9":["CCTV-9","CCTV-09","CCTV9-çºªå½•","CCTV-9çºªå½•","CCTV-9çºªå½•","CCTV9HD","cctv9HD","CCTV-9é«˜æ¸…","cctv-9HD","CCTV9è®°å½•é«˜æ¸…","cctv9"],
    "CCTV10":["CCTV-10","CCTV10-ç§‘æ•™","CCTV-10ç§‘æ•™","CCTV-10ç§‘æ•™","CCTV10HD","CCTV-10é«˜æ¸…","CCTV-10HD","CCTV-10é«˜æ¸…","CCTV10ç§‘æ•™é«˜æ¸…","cctv10"],
    "CCTV11":["CCTV-11","CCTV11-æˆæ›²","CCTV-11æˆæ›²","CCTV-11æˆæ›²","CCTV11HD","cctv11HD","CCTV-11HD","cctv-11HD","CCTV11æˆæ›²é«˜æ¸…","cctv11"],
    "CCTV12":["CCTV-12","CCTV12-ç¤¾ä¼šä¸æ³•","CCTV-12ç¤¾ä¼šä¸æ³•","CCTV-12ç¤¾ä¼šä¸æ³•","CCTV12HD","CCTV-12é«˜æ¸…","CCTV-12HD","cctv-12HD","CCTV12ç¤¾ä¼šä¸æ³•é«˜æ¸…","cctv12"],
    "CCTV13":["CCTV-13","CCTV13-æ–°é—»","CCTV-13æ–°é—»","CCTV-13æ–°é—»","CCTV13HD","cctv13HD","CCTV-13HD","cctv-13HD","CCTV13æ–°é—»é«˜æ¸…","cctv13"],
    "CCTV14":["CCTV-14","CCTV14-å°‘å„¿","CCTV-14å°‘å„¿","CCTV-14å°‘å„¿","CCTV14HD","CCTV-14é«˜æ¸…","CCTV-14HD","CCTVå°‘å„¿","CCTV14å°‘å„¿é«˜æ¸…","cctv14"],
    "CCTV15":["CCTV-15","CCTV15-éŸ³ä¹","CCTV-15éŸ³ä¹","CCTV-15éŸ³ä¹","CCTV15HD","cctv15HD","CCTV-15HD","cctv-15HD","CCTV15éŸ³ä¹é«˜æ¸…","cctv15"],
    "CCTV16":["CCTV-16","CCTV-16HD","CCTV-164K","CCTV-16å¥¥æ—åŒ¹å…‹","CCTV16HD","cctv16HD","CCTV-16HD","cctv-16HD","CCTV16å¥¥æ—åŒ¹å…‹é«˜æ¸…","cctv16"],
    "CCTV17":["CCTV-17","CCTV17é«˜æ¸…","CCTV17HD","CCTV-17å†œä¸šå†œæ‘","CCTV17HD","cctv17HD","CCTV-17HD","cctv-17HD","CCTV17å†œä¸šå†œæ‘é«˜æ¸…","cctv17"],
}

RESULTS_PER_CHANNEL = 20

def load_urls():
    """ä» GitHub ä¸‹è½½ IPTV IP æ®µåˆ—è¡¨"""
    import requests
    try:
        resp = requests.get(URL_FILE, timeout=5)
        resp.raise_for_status()
        urls = [line.strip() for line in resp.text.splitlines() if line.strip()]
        print(f"ğŸ“¡ å·²åŠ è½½ {len(urls)} ä¸ªåŸºç¡€ URL")
        return urls
    except Exception as e:
        print(f"âŒ ä¸‹è½½ {URL_FILE} å¤±è´¥: {e}")
        exit()

async def generate_urls(url):
    modified_urls = []

    ip_start = url.find("//") + 2
    ip_end = url.find(":", ip_start)

    base = url[:ip_start]
    ip_prefix = url[ip_start:ip_end].rsplit('.', 1)[0]
    port = url[ip_end:]

    json_paths = [
    "/iptv/live/1000.json?key=txiptv",
    "/iptv/live/1001.json?key=txiptv",
    "/ZHGXTV/Public/json/live_interface.txt",
]

    for i in range(1, 256):
        ip = f"{base}{ip_prefix}.{i}{port}"
        for path in json_paths:
            modified_urls.append(f"{ip}{path}")

    return modified_urls

async def check_url(session, url, semaphore):
    async with semaphore:
        try:
            async with session.get(url, timeout=1) as resp:#===========================JSONè®¿é—®æ—¶é—´
                if resp.status == 200:
                    return url
        except:
            return None

async def fetch_json(session, url, semaphore):
    async with semaphore:
        try:
            async with session.get(url, timeout=2) as resp:
                data = await resp.json()
                results = []
                for item in data.get('data', []):
                    name = item.get('name')
                    urlx = item.get('url')
                    if not name or not urlx or ',' in urlx:
                        continue

                    if not urlx.startswith("http"):
                        urlx = urljoin(url, urlx)

                    for std_name, aliases in CHANNEL_MAPPING.items():
                        if name in aliases:
                            name = std_name
                            break

                    results.append((name, urlx))
                return results
        except:
            return []

async def measure_speed(session, url, semaphore):
    async with semaphore:
        start = time.time()
        try:
            async with session.head(url, timeout=2) as resp:  # =======================é¢‘é“æµ‹é€Ÿç”¨æ—¶
                if resp.status == 200:
                    return int((time.time() - start) * 1000)
                else:
                    return 999999
        except:
            return 999999

def is_valid_stream(url):
    if url.startswith(("rtp://", "udp://", "rtsp://")):
        return False
    if "239." in url:
        return False
    if url.startswith(("http://16.", "http://10.", "http://192.168.")):
        return False
    if "/paiptv/" in url or "/00/SNM/" in url or "/00/CHANNEL" in url:
        return False
    valid_ext = (".m3u8", ".ts", ".flv", ".mp4", ".mkv")
    return url.startswith("http") and any(ext in url for ext in valid_ext)

async def main():
    print("ğŸš€ å¼€å§‹è¿è¡Œ ITVlist è„šæœ¬")
    semaphore = asyncio.Semaphore(150)  # ==============================================å¹¶å‘é™åˆ¶

    urls = load_urls()
    
    async with aiohttp.ClientSession() as session:
        all_urls = []
        for url in urls:
            modified_urls = await generate_urls(url)
            all_urls.extend(modified_urls)
        print(f"ğŸ” ç”Ÿæˆå¾…æ‰«æ URL å…±: {len(all_urls)} ä¸ª")

        print("â³ å¼€å§‹æ£€æµ‹å¯ç”¨ JSON API...")
        tasks = [check_url(session, u, semaphore) for u in all_urls]
        valid_urls = [r for r in await asyncio.gather(*tasks) if r]
        print(f"âœ… å¯ç”¨ JSON åœ°å€: {len(valid_urls)} ä¸ª")
        for u in valid_urls:
            print(f"  - {u}")

        print("ğŸ“¥ å¼€å§‹æŠ“å–èŠ‚ç›®å• JSON...")
        tasks = [fetch_json(session, u, semaphore) for u in valid_urls]
        results = []
        fetched = await asyncio.gather(*tasks)
        for sublist in fetched:
            results.extend(sublist)
        print(f"ğŸ“º æŠ“åˆ°é¢‘é“æ€»æ•°: {len(results)} æ¡")

        final_results = [(name, url, 0) for name, url in results]

        final_results = [
            (name, url, speed)
            for name, url, speed in final_results
            if is_valid_stream(url)
        ]

        print("ğŸš€ å¼€å§‹æµ‹é€Ÿé¢‘é“æº...")
        speed_tasks = [measure_speed(session, url, semaphore) for (_, url, _) in final_results]
        speeds = await asyncio.gather(*speed_tasks)
        final_results = [
            (name, url, speed)
            for (name, url, _), speed in zip(final_results, speeds)
        ]

        final_results.sort(key=lambda x: x[2])

        itv_dict = {cat: [] for cat in CHANNEL_CATEGORIES}
        for name, url, speed in final_results:
            for cat, channels in CHANNEL_CATEGORIES.items():
                if name in channels:
                    itv_dict[cat].append((name, url, speed))
                    break

        for cat in CHANNEL_CATEGORIES:
            print(f"ğŸ“¦ åˆ†ç±»ã€Š{cat}ã€‹æ‰¾åˆ° {len(itv_dict[cat])} æ¡é¢‘é“")

        beijing_now = datetime.datetime.now(
            datetime.timezone(datetime.timedelta(hours=8))
        ).strftime("%y/%m/%d-%H:%M:%S")
        disclaimer_url = "http://kakaxi.indevs.in/LOGO/Disclaimer.mp4"

        with open("itvlist.txt", 'w', encoding='utf-8') as f:
            f.write(f"æ›´æ–°æ—¶é—´: {beijing_now}ï¼ˆåŒ—äº¬æ—¶é—´ï¼‰\n\n")
            #f.write("æ›´æ–°æ—¶é—´,#genre#\n")
            #f.write(f"{beijing_now},{disclaimer_url}\n\n")

            for cat in CHANNEL_CATEGORIES:
                f.write(f"{cat},#genre#\n")
                for ch in CHANNEL_CATEGORIES[cat]:
                    ch_items = [x for x in itv_dict[cat] if x[0] == ch]
                    ch_items = ch_items[:RESULTS_PER_CHANNEL]
                    for item in ch_items:
                        f.write(f"{item[0]},{item[1]}\n")
            f.write(f"æ›´æ–°æ—¶é—´,#genre#\n\n")
            f.write(f"{beijing_now},{disclaimer_url}\n\n")
        print("ğŸ‰ itvlist.txt å·²ç”Ÿæˆå®Œæˆï¼")

if __name__ == "__main__":
    asyncio.run(main())
